{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-develop-word-embeddings-with-gensim.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPIQp6YvUCyJahnb5y4HWs2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning-for-nlp-by-jason-brownlee/blob/part-3-word-embeddings/1_develop_word_embeddings_with_gensim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HIt3zVWx2sg",
        "colab_type": "text"
      },
      "source": [
        "# Develop Word Embeddings with Gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nxZK9MTyBg0",
        "colab_type": "text"
      },
      "source": [
        "Word embeddings are a modern approach for representing text in natural language processing. Embedding algorithms like Word2Vec and GloVe are key to the state-of-the-art results achieved by neural network models on natural language processing problems like machine translation.\n",
        "\n",
        "We will discover how to train and load word embedding models for natural language processing applications in Python using Gensim."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYoopBd1yqmS",
        "colab_type": "text"
      },
      "source": [
        "## Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A80iB_D7yrlC",
        "colab_type": "text"
      },
      "source": [
        "A word embedding is an approach to provide a dense vector representation of words that capture something about their meaning. Word embeddings are an improvement over simpler bag-of-word model word encoding schemes like word counts and frequencies that result in large and sparse vectors (mostly 0 values) that describe documents but not the meaning of the words.\n",
        "\n",
        "Word embeddings work by using an algorithm to train a set of fixed-length dense and continuous-valued vectors based on a large corpus of text. Each word is represented by a point in the embedding space and these points are learned and moved around based on the words that surround the target word. It is defining a word by the company that it keeps that allows the word embedding to learn something about the meaning of words. The vector space representation of the words provides a projection where words with similar meanings are locally clustered within the space.\n",
        "\n",
        "The use of word embeddings over other text representations is one of the key methods that has led to breakthrough performance with deep neural networks on problems like machine translation.\n",
        "\n",
        "We are going to look at how to use two different word embedding\n",
        "methods called Word2Vec by researchers at Google and GloVe by researchers at Stanford."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO2y6dXLzeZd",
        "colab_type": "text"
      },
      "source": [
        "## Gensim Python Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zT_8lwtzfW3",
        "colab_type": "text"
      },
      "source": [
        "Gensim is an open source Python library for natural language processing, with a focus on topic modeling. It is billed as \"topic modeling for humans\".\n",
        "\n",
        "It is not an everything-including-the-kitchen-sink NLP research library (like NLTK); instead, Gensim is a mature, focused, and efficient suite of NLP tools for topic modeling. It supports an implementation of the Word2Vec word embedding for learning new word vectors from text.\n",
        "\n",
        "It also provides tools for loading pre-trained word embeddings in a few formats and for making use and querying a loaded embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOBw6P3k0O-g",
        "colab_type": "text"
      },
      "source": [
        "## Develop Word2Vec Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv745H150Pvj",
        "colab_type": "text"
      },
      "source": [
        "Word2Vec is one algorithm for learning a word embedding from a text corpus. There are two main training algorithms that can be used to learn the embedding from text:-\n",
        "* **Continuous Bag-of-Words (CBOW)**\n",
        "* **Skip-gram**\n",
        "\n",
        "We will not get into the algorithms other than to say that they generally look at a window of words for each target word to provide context and in turn meaning for words.\n",
        "\n",
        "Word2Vec models require a lot of text, e.g. the entire Wikipedia corpus. Nevertheless, we will demonstrate the principles using a small in-memory example of text. \n",
        "\n",
        "Gensim provides the Word2Vec class for working with a Word2Vec model. Learning a word embedding from text involves loading and organizing the text into sentences and providing them to the constructor of a new Word2Vec() instance.\n",
        "\n",
        "```python\n",
        "sentences = ...\n",
        "model = Word2Vec(sentences)\n",
        "```\n",
        "\n",
        "Specifically, each sentence must be tokenized, meaning divided into words and prepared (e.g. perhaps pre-filtered and perhaps converted to a preferred case). The sentences could be text loaded into memory, or an iterator that progressively loads text, required for very large text corpora. \n",
        "\n",
        "There are many parameters on this constructor; a few noteworthy arguments you may wish to configure are:\n",
        "\n",
        "* **size**: (default 100) The number of dimensions of the embedding, e.g. the length of the dense vector to represent each token (word).\n",
        "* **window**: (default 5) The maximum distance between a target word and words around the target word.\n",
        "* **min count**: (default 5) The minimum count of words to consider when training the model; words with an occurrence less than this count will be ignored.\n",
        "* **workers**: (default 3) The number of threads to use while training.\n",
        "* **sg**: (default 0 or CBOW) The training algorithm, either CBOW (0) or skip gram (1).\n",
        "\n",
        "The defaults are often good enough when just getting started. If you have a lot of cores, as most modern computers do, I strongly encourage you to increase workers to match the number of cores (e.g. 8).\n",
        "\n",
        "After the model is trained, it is accessible via the wv attribute. This is the actual word vector model in which queries can be made. \n",
        "\n",
        "For example, you can print the learned vocabulary of tokens (words) as follows:\n",
        "\n",
        "```python\n",
        "words = list(model.wv.vocab)\n",
        "print(words)\n",
        "```\n",
        "\n",
        "You can review the embedded vector for a specific token as follows:\n",
        "\n",
        "```python\n",
        "print(model['word'])\n",
        "```\n",
        "\n",
        "Finally, a trained model can then be saved to file by calling the save word2vec format() function on the word vector model. By default, the model is saved in a binary format to save space.\n",
        "\n",
        "```python\n",
        "model.wv.save_word2vec_format('model.bin')\n",
        "```\n",
        "\n",
        "When getting started, you can save the learned model in ASCII format and review the contents. You can do this by setting binary=False when calling the save word2vec format() function.\n",
        "\n",
        "```python\n",
        "model.wv.save_word2vec_format('model.txt', binary=False)\n",
        "```\n",
        "\n",
        "The saved model can then be loaded again by calling the Word2Vec.load() function.\n",
        "\n",
        "```python\n",
        "model = Word2Vec.load('model.bin')\n",
        "```\n",
        "\n",
        "We can tie all of this together with a worked example. Rather than loading a large text document or corpus from file, we will work with a small, in-memory list of pre-tokenized sentences. \n",
        "\n",
        "The model is trained and the minimum count for words is set to 1 so that no words are ignored. After the model is learned, we summarize, print the vocabulary, then print a single vector for the word \"sentence\". \n",
        "\n",
        "Finally, the model is saved to a file in binary format, loaded,\n",
        "and then summarized.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaJbZO603i7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD-RTt4O3v5A",
        "colab_type": "code",
        "outputId": "14b7258d-9fbb-47a1-c8ed-b0d1f0e9b4f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "# define training data\n",
        "sentences = [\n",
        "  ['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n",
        "  ['this', 'is', 'the', 'second', 'sentence'],\n",
        "  ['yet', 'another', 'sentence'],\n",
        "  ['one', 'more', 'sentence'],\n",
        "  ['and', 'the', 'final', 'sentence']         \n",
        "]\n",
        "\n",
        "# train model\n",
        "model = Word2Vec(sentences, min_count=1)\n",
        "\n",
        "# summarize the loaded model\n",
        "print(model)\n",
        "\n",
        "# summarize vocabulary\n",
        "words = list(model.wv.vocab)\n",
        "print(words)\n",
        "\n",
        "# access vector for one word\n",
        "print(model['sentence'])\n",
        "\n",
        "# save model\n",
        "model.save('model.bin')\n",
        "\n",
        "# load model\n",
        "new_model = Word2Vec.load('model.bin')\n",
        "print(new_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=14, size=100, alpha=0.025)\n",
            "['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec', 'second', 'yet', 'another', 'one', 'more', 'and', 'final']\n",
            "[-0.00430853 -0.0010612  -0.00357043 -0.00197735  0.00101788 -0.00235918\n",
            "  0.00463937 -0.00377156  0.00130901 -0.00418384 -0.00316141 -0.00134712\n",
            " -0.00272129  0.00435421 -0.00056567 -0.00234536 -0.00425877  0.00392617\n",
            "  0.00442912 -0.00308037  0.00485346 -0.00371804  0.00076224  0.0004597\n",
            " -0.00173547 -0.00416696 -0.00301806  0.0021823   0.00284618  0.00062046\n",
            "  0.00185371 -0.00080637 -0.00491324 -0.0041652  -0.00437492 -0.00403443\n",
            " -0.00348326 -0.00366579  0.00272375 -0.00273549  0.00140199 -0.00262868\n",
            "  0.00167049 -0.00489838  0.00257384  0.00087063  0.00026339 -0.00349258\n",
            " -0.00273281 -0.00287726  0.00060782 -0.00323993 -0.00340895  0.00182926\n",
            " -0.00014312 -0.00092501 -0.00302666  0.00321592 -0.00160415 -0.00287781\n",
            "  0.00051921 -0.00474417  0.00483934  0.00219409  0.00229238 -0.00028669\n",
            " -0.00054155 -0.00302478 -0.0018981  -0.00319882  0.00302625  0.00438174\n",
            " -0.00348394  0.00282924  0.00416329 -0.00488567 -0.00093039  0.00194827\n",
            "  0.00499831  0.00405092  0.00242022  0.00200055 -0.00365856  0.00333491\n",
            " -0.00251614  0.0028057  -0.0023997   0.00402034 -0.00402152 -0.0010793\n",
            " -0.00304186 -0.00263196 -0.00471376  0.00279196 -0.00083406 -0.00195553\n",
            "  0.00052395 -0.00417565 -0.00022089  0.00396145]\n",
            "Word2Vec(vocab=14, size=100, alpha=0.025)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZcUa6XwyfHT",
        "colab_type": "code",
        "outputId": "28ce706c-39be-4124-abde-1421246156f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "new_model.wv.vocab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'and': <gensim.models.keyedvectors.Vocab at 0x7fa7c43d07b8>,\n",
              " 'another': <gensim.models.keyedvectors.Vocab at 0x7fa7c43d0668>,\n",
              " 'final': <gensim.models.keyedvectors.Vocab at 0x7fa7c43d0828>,\n",
              " 'first': <gensim.models.keyedvectors.Vocab at 0x7fa7c43d0438>,\n",
              " 'for': <gensim.models.keyedvectors.Vocab at 0x7fa7c43d04e0>,\n",
              " 'is': <gensim.models.keyedvectors.Vocab at 0x7fa7c43d0358>,\n",
              " 'more': <gensim.models.keyedvectors.Vocab at 0x7fa7c43d0748>,\n",
              " 'one': <gensim.models.keyedvectors.Vocab at 0x7fa7c43d06d8>,\n",
              " 'second': <gensim.models.keyedvectors.Vocab at 0x7fa7c43d0588>,\n",
              " 'sentence': <gensim.models.keyedvectors.Vocab at 0x7fa7c43d0470>,\n",
              " 'the': <gensim.models.keyedvectors.Vocab at 0x7fa7c43d03c8>,\n",
              " 'this': <gensim.models.keyedvectors.Vocab at 0x7fa7c43d0278>,\n",
              " 'word2vec': <gensim.models.keyedvectors.Vocab at 0x7fa7c43d0518>,\n",
              " 'yet': <gensim.models.keyedvectors.Vocab at 0x7fa7c43d05f8>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cD0lioSyya7",
        "colab_type": "code",
        "outputId": "753e2a9c-d14f-4671-c1ab-57a288756148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "new_model.wv.vector_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8D-Zf9Dy5PM",
        "colab_type": "code",
        "outputId": "a26ad8e3-3690-44c4-918c-4b8b8d26e40c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "new_model.wv.vectors"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-4.3085273e-03, -1.0612011e-03, -3.5704260e-03, ...,\n",
              "        -4.1756546e-03, -2.2089377e-04,  3.9614462e-03],\n",
              "       [ 1.4891515e-03, -2.6343467e-03,  2.9473484e-03, ...,\n",
              "        -4.0547433e-03, -1.7627738e-03,  3.8972714e-03],\n",
              "       [ 4.3983115e-03,  9.0348138e-04,  3.3005201e-03, ...,\n",
              "        -2.0481939e-03, -3.5778803e-03, -3.2986866e-03],\n",
              "       ...,\n",
              "       [-4.1768504e-03, -2.0467669e-03,  2.9037585e-03, ...,\n",
              "        -3.4164891e-03,  3.9712605e-03, -4.2816061e-03],\n",
              "       [-4.4812830e-03, -7.0602854e-04, -3.6400117e-03, ...,\n",
              "        -2.2377546e-03,  3.6140149e-03, -4.4836070e-05],\n",
              "       [ 3.8796724e-03, -7.7581120e-04,  1.7818528e-03, ...,\n",
              "        -4.9471087e-03,  4.3437663e-03,  1.5712756e-04]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6Hegtlpy-VN",
        "colab_type": "code",
        "outputId": "fdca84a2-ba35-4b2f-c92a-fdad6b4b6321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "words = list(new_model.wv.vocab)\n",
        "words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this',\n",
              " 'is',\n",
              " 'the',\n",
              " 'first',\n",
              " 'sentence',\n",
              " 'for',\n",
              " 'word2vec',\n",
              " 'second',\n",
              " 'yet',\n",
              " 'another',\n",
              " 'one',\n",
              " 'more',\n",
              " 'and',\n",
              " 'final']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DKzJUPJzZhF",
        "colab_type": "code",
        "outputId": "498e1bc3-35d8-4349-db22-91e28dcd21dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "print(new_model['sentence'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.00430853 -0.0010612  -0.00357043 -0.00197735  0.00101788 -0.00235918\n",
            "  0.00463937 -0.00377156  0.00130901 -0.00418384 -0.00316141 -0.00134712\n",
            " -0.00272129  0.00435421 -0.00056567 -0.00234536 -0.00425877  0.00392617\n",
            "  0.00442912 -0.00308037  0.00485346 -0.00371804  0.00076224  0.0004597\n",
            " -0.00173547 -0.00416696 -0.00301806  0.0021823   0.00284618  0.00062046\n",
            "  0.00185371 -0.00080637 -0.00491324 -0.0041652  -0.00437492 -0.00403443\n",
            " -0.00348326 -0.00366579  0.00272375 -0.00273549  0.00140199 -0.00262868\n",
            "  0.00167049 -0.00489838  0.00257384  0.00087063  0.00026339 -0.00349258\n",
            " -0.00273281 -0.00287726  0.00060782 -0.00323993 -0.00340895  0.00182926\n",
            " -0.00014312 -0.00092501 -0.00302666  0.00321592 -0.00160415 -0.00287781\n",
            "  0.00051921 -0.00474417  0.00483934  0.00219409  0.00229238 -0.00028669\n",
            " -0.00054155 -0.00302478 -0.0018981  -0.00319882  0.00302625  0.00438174\n",
            " -0.00348394  0.00282924  0.00416329 -0.00488567 -0.00093039  0.00194827\n",
            "  0.00499831  0.00405092  0.00242022  0.00200055 -0.00365856  0.00333491\n",
            " -0.00251614  0.0028057  -0.0023997   0.00402034 -0.00402152 -0.0010793\n",
            " -0.00304186 -0.00263196 -0.00471376  0.00279196 -0.00083406 -0.00195553\n",
            "  0.00052395 -0.00417565 -0.00022089  0.00396145]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UTDUDVbzkV7",
        "colab_type": "code",
        "outputId": "18a54d07-c009-4e17-c104-5751b30213b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        }
      },
      "source": [
        "print(new_model['final'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 3.8796724e-03 -7.7581120e-04  1.7818528e-03 -1.9761817e-05\n",
            " -4.8673004e-03  2.5883447e-03  4.4909581e-03 -4.2883395e-03\n",
            " -3.2133108e-04 -1.4478170e-03  1.3506640e-03  3.2140932e-03\n",
            " -2.8894213e-03  6.1481632e-04  4.6842210e-03  3.4568678e-03\n",
            "  4.7807409e-03 -2.2466546e-03 -6.2651181e-04  4.8206518e-03\n",
            " -1.7211207e-03 -2.8372414e-03  2.1281305e-03 -3.3642873e-03\n",
            " -3.4641868e-03  8.1896794e-04  3.9562634e-03  4.8880153e-03\n",
            " -1.4392596e-03 -3.7133589e-03 -2.2571457e-04  2.3168069e-03\n",
            "  2.4909507e-03 -1.3405925e-03  3.6265196e-03  2.9054724e-03\n",
            " -2.8672514e-03  2.9091579e-03  4.4441326e-03  3.1988446e-03\n",
            "  2.3390970e-03 -3.1612534e-03 -8.1592589e-04 -1.1796877e-03\n",
            " -4.6358840e-04 -3.6548402e-03  1.0328239e-03 -3.1002525e-03\n",
            " -2.2621928e-03  1.1083053e-03 -2.5899974e-03 -2.1482649e-04\n",
            "  1.9820544e-03 -1.5525251e-03  4.6706358e-03  3.5251135e-03\n",
            " -1.5467710e-03  4.5245336e-03  1.0104139e-03  4.9600010e-03\n",
            "  2.3403463e-03 -3.1592385e-03 -4.4357674e-03 -1.5747731e-03\n",
            " -4.6933461e-03  1.8019983e-04  2.8581107e-03 -2.9681893e-03\n",
            "  3.7228961e-03  3.1018213e-03 -2.3480929e-03 -5.9350219e-04\n",
            " -3.2574302e-04 -1.7269847e-03 -7.7459018e-04 -4.7974717e-03\n",
            "  3.7403275e-05 -4.5053326e-03  3.7577760e-03  2.1400871e-03\n",
            " -2.4602201e-03  2.3199318e-03  2.4685962e-03  6.7304895e-04\n",
            " -1.7836078e-03  3.8613977e-03 -2.4036730e-03  3.4587313e-03\n",
            "  3.7389626e-03 -3.0103186e-03 -9.0352644e-04  1.6547296e-03\n",
            " -2.1373488e-03 -2.4817879e-03  4.2498400e-03  2.1719260e-03\n",
            "  3.6843191e-03 -4.9471087e-03  4.3437663e-03  1.5712756e-04]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1EkANYE5GH1",
        "colab_type": "text"
      },
      "source": [
        "You can see that with a little work to prepare your text document, you can create your own word embedding very easily with Gensim."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSHy8vrc5H6o",
        "colab_type": "text"
      },
      "source": [
        "## Visualize Word Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agxmqa-n5LUm",
        "colab_type": "text"
      },
      "source": [
        "After you learn word embedding for your text data, it can be nice to explore it with visualization. You can use classical projection methods to reduce the high-dimensional word vectors to two-dimensional plots and plot them on a graph. The visualizations can provide a qualitative diagnostic for your learned model. \n",
        "\n",
        "We can retrieve all of the vectors from a trained model as follows:\n",
        "\n",
        "```python\n",
        "X = model[model.wv.vocab]\n",
        "```\n",
        "\n",
        "We can then train a projection method on the vectors, such as those methods offered in scikit-learn, then use Matplotlib to plot the projection as a scatter plot. Let's look at an example\n",
        "with Principal Component Analysis or PCA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsDXAlP40tUf",
        "colab_type": "text"
      },
      "source": [
        "## Plot Word Vectors Using PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI0ONnsG0urx",
        "colab_type": "text"
      },
      "source": [
        "We can create a 2-dimensional PCA model of the word vectors using the scikit-learn PCA class as follows.\n",
        "\n",
        "```python\n",
        "pca = PCA(n_components=2)\n",
        "result = pca.fit_transform(X)\n",
        "```\n",
        "\n",
        "The resulting projection can be plotted using Matplotlib as follows, pulling out the two dimensions as x and y coordinates.\n",
        "\n",
        "```python\n",
        "pyplot.scatter(result[:, 0], result[:, 1])\n",
        "```\n",
        "\n",
        "We can go one step further and annotate the points on the graph with the words themselves.\n",
        "\n",
        "A crude version without any nice offsets looks as follows.\n",
        "\n",
        "```python\n",
        "words = list(model.wv.vocab)\n",
        "for i, word in enumerate(words):\n",
        "  pyplot.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ppnnlre1cfK",
        "colab_type": "text"
      },
      "source": [
        "Putting this all together with the model from the previous section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRJefoDP4tCs",
        "colab_type": "code",
        "outputId": "72d1151d-5e09-4d7b-d97e-e8f6ba652cd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# define training data\n",
        "sentences = [\n",
        "  ['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n",
        "  ['this', 'is', 'the', 'second', 'sentence'],\n",
        "  ['yet', 'another', 'sentence'],\n",
        "  ['one', 'more', 'sentence'],\n",
        "  ['and', 'the', 'final', 'sentence']         \n",
        "]\n",
        "\n",
        "# train model\n",
        "model = Word2Vec(sentences, min_count=1)\n",
        "\n",
        "# fit a 2d PCA model to the vectors\n",
        "X = model[model.wv.vocab]\n",
        "pca = PCA(n_components=2)\n",
        "results = pca.fit_transform(X)\n",
        "\n",
        "# create a scatter plot of the projection\n",
        "pyplot.scatter(results[:, 0], results[:, 1])\n",
        "words = list(model.wv.vocab)\n",
        "for i, word in enumerate(words):\n",
        "  pyplot.annotate(word, xy=(results[i, 0], results[i, 1]))\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkO9fd3T9sFE",
        "colab_type": "text"
      },
      "source": [
        "## Load Google's Word2Vec Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvxDv2ZM9s-6",
        "colab_type": "text"
      },
      "source": [
        "Training your own word vectors may be the best approach for a given NLP problem. But it can take a long time, a fast computer with a lot of RAM and disk space, and perhaps some expertise in finessing the input data and training algorithm. An alternative is to simply use an existing pre-trained word embedding. Along with the paper and code for Word2Vec, Google also published a pre-trained Word2Vec model on the Word2Vec Google Code Project.\n",
        "\n",
        "A pre-trained model is nothing more than a file containing tokens and their associated word vectors. The pre-trained Google Word2Vec model was trained on Google news data (about 100 billion words); it contains 3 million words and phrases and was fit using 300-dimensional word vectors. It is a 1.53 Gigabyte file.\n",
        "\n",
        "The Gensim library provides tools to load this file. Specifically, you can call the KeyedVectors.load word2vec format() function to load this model into memory.\n",
        "\n",
        "```python\n",
        "from gensim.models import KeyedVectors\n",
        "filename = 'GoogleNews-vectors-negative300.bin'\n",
        "model = KeyedVectors.load_word2vec_format(filename, binary=True)\n",
        "```\n",
        "\n",
        "Another interesting thing that you can do is do a little linear algebra arithmetic with words. \n",
        "\n",
        "For example, a popular example described in lectures and introduction papers is:\n",
        "\n",
        "```python\n",
        "queen = (king - man) + woman\n",
        "```\n",
        "\n",
        "That is the word queen is the closest word given the subtraction of the notion of man from king and adding the word woman. The man-ness in king is replaced with woman-ness to give us queen. A very cool concept. \n",
        "\n",
        "Gensim provides an interface for performing these types of\n",
        "operations in the most similar() function on the trained or loaded model.\n",
        "\n",
        "```python\n",
        "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
        "print(result)\n",
        "```\n",
        "\n",
        "We will download Google Word2Vec model file from web."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOhjstHy3uCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tqdm\n",
        "import requests\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hKFdkYUBoAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install pugnlp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqCM_O8zBuy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pugnlp.futil import path_status, find_files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRWHdJHMAmg-",
        "colab_type": "text"
      },
      "source": [
        "Download the Google Word2Vec model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7wkNlGk-eNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BIG_URLS = {\n",
        "    'w2v': ('https://www.dropbox.com/s/965dir4dje0hfi4/GoogleNews-vectors-negative300.bin.gz?dl=1', 1647046227),\n",
        "    'g2v': ('http://nlp.stanford.edu/data/glove.6B.zip',)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPDUmXwR_0XN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# These functions are part of the nlpia package which can be pip installed and run from there.\n",
        "def dropbox_basename(url):\n",
        "    filename = os.path.basename(url)\n",
        "    match = re.findall(r'\\?dl=[0-9]$', filename)\n",
        "    if match:\n",
        "        return filename[:-len(match[0])]\n",
        "    return filename\n",
        "\n",
        "def download_file(url, data_path='.', filename=None, size=None, chunk_size=4096, verbose=True):\n",
        "    \"\"\"Uses stream=True and a reasonable chunk size to be able to download large (GB) files over https\"\"\"\n",
        "    if filename is None:\n",
        "        filename = dropbox_basename(url)\n",
        "    file_path = os.path.join(data_path, filename)\n",
        "    if url.endswith('?dl=0'):\n",
        "        url = url[:-1] + '1'  # noninteractive download\n",
        "    if verbose:\n",
        "        tqdm_prog = tqdm\n",
        "        print('requesting URL: {}'.format(url))\n",
        "    else:\n",
        "        tqdm_prog = no_tqdm\n",
        "    r = requests.get(url, stream=True, allow_redirects=True)\n",
        "    size = r.headers.get('Content-Length', None) if size is None else size\n",
        "    print('remote size: {}'.format(size))\n",
        "\n",
        "    stat = path_status(file_path)\n",
        "    print('local size: {}'.format(stat.get('size', None)))\n",
        "    if stat['type'] == 'file' and stat['size'] == size:  # TODO: check md5 or get the right size of remote file\n",
        "        r.close()\n",
        "        return file_path\n",
        "\n",
        "    print('Downloading to {}'.format(file_path))\n",
        "\n",
        "    with open(file_path, 'wb') as f:\n",
        "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
        "            if chunk:  # filter out keep-alive chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "    r.close()\n",
        "    return file_path\n",
        "\n",
        "def untar(fname):\n",
        "    if fname.endswith(\"tar.gz\"):\n",
        "        with tarfile.open(fname) as tf:\n",
        "            tf.extractall()\n",
        "    else:\n",
        "        print(\"Not a tar.gz file: {}\".format(fname))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrQYEMeRBLZU",
        "colab_type": "code",
        "outputId": "eace158d-f2e6-43fe-fb23-ec8b78bebb56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "download_file(BIG_URLS['w2v'][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "requesting URL: https://www.dropbox.com/s/965dir4dje0hfi4/GoogleNews-vectors-negative300.bin.gz?dl=1\n",
            "remote size: 1647046227\n",
            "local size: 1647046227\n",
            "Downloading to ./GoogleNews-vectors-negative300.bin.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./GoogleNews-vectors-negative300.bin.gz'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mpk_YUroCW9h",
        "colab_type": "text"
      },
      "source": [
        "We can put all of this together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLA4Phs_BPah",
        "colab_type": "code",
        "outputId": "0d21a4c0-33c3-4857-8024-9bc4d1375a88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "filename = 'GoogleNews-vectors-negative300.bin.gz'\n",
        "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwEwRq7UC4rv",
        "colab_type": "code",
        "outputId": "37e658dd-2e83-4188-d21e-731b072762f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# calculate: (king - man) + woman = ?\n",
        "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1) # find the top 1 most similar words\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[('queen', 0.7118192911148071)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIdvI1xKFPHw",
        "colab_type": "code",
        "outputId": "3b3ba8db-3912-4dc9-be33-09731863e663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# find the top 2 most similar words\n",
        "result = model.most_similar_cosmul(positive=['woman', 'king'], negative=['man'], topn=2) \n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('queen', 0.9314123392105103), ('monarch', 0.858533501625061)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1QX4wgaGOYL",
        "colab_type": "code",
        "outputId": "cb291723-2fe1-491a-ce7b-0132dec78f77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# find the top-N most similar words\n",
        "result = model.most_similar_cosmul(positive=['woman', 'king'], negative=['man']) \n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('queen', 0.9314123392105103), ('monarch', 0.858533501625061), ('princess', 0.8476566076278687), ('Queen_Consort', 0.8150269985198975), ('queens', 0.8099815249443054), ('crown_prince', 0.808997631072998), ('royal_palace', 0.8027306795120239), ('monarchy', 0.801961362361908), ('prince', 0.800979733467102), ('empress', 0.7958388328552246)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KpIRVxNG3BK",
        "colab_type": "code",
        "outputId": "2417f0a9-bbe0-43b9-d0c1-dad142f6f720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "# filter not similer word\n",
        "print(model.doesnt_match('breakfast cereal dinner lunch').split())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['k']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBeLi1ZeHQIg",
        "colab_type": "code",
        "outputId": "3fb3302b-d364-47ee-936d-6157ed1a230c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "similarity = model.similarity('woman', 'man')\n",
        "print(similarity)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.76640123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_rZekPlHyJn",
        "colab_type": "code",
        "outputId": "a2971aae-7955-49b4-a2c6-4074c392a92d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "result = model.similar_by_word('cat')\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[('cats', 0.8099379539489746), ('dog', 0.7609456777572632), ('kitten', 0.7464985251426697), ('feline', 0.7326233983039856), ('beagle', 0.7150583267211914), ('puppy', 0.7075453996658325), ('pup', 0.6934291124343872), ('pet', 0.6891531348228455), ('felines', 0.6755931377410889), ('chihuahua', 0.6709762215614319)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmKvAeLaIEgm",
        "colab_type": "code",
        "outputId": "cff8c652-6767-4a7a-a706-ca366613f7d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sentence_obama = 'Obama speaks to the media in Illinois'.lower().split()\n",
        "sentence_president = 'The president greets the press in Chicago'.lower().split()\n",
        "similarity = model.wmdistance(sentence_obama, sentence_president)\n",
        "print(similarity)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2813313673465077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K0OGNaLIrTK",
        "colab_type": "code",
        "outputId": "f9ec2b5c-fbaa-48df-fb1c-b2f9cb467783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "distance = model.distance(\"media\", \"media\")\n",
        "print(distance)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8OEG-bFKCLp",
        "colab_type": "text"
      },
      "source": [
        "## Load Stanford's GloVe Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlIFaFKhKDF6",
        "colab_type": "text"
      },
      "source": [
        "Like Word2Vec, the GloVe researchers also provide pre-trained word vectors, in this case, a great selection to choose from. You can download the GloVe pre-trained word vectors and load them easily with Gensim. The first step is to convert the GloVe file format to the Word2Vec file format. The only difference is the addition of a small header line. This can be done by calling\n",
        "the glove2word2vec() function.\n",
        "\n",
        "```python\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "glove_input_file = 'glove.txt'\n",
        "word2vec_output_file = 'word2vec.txt'\n",
        "glove2word2vec(glove_input_file, word2vec_output_file)\n",
        "```\n",
        "\n",
        "Once converted, the file can be loaded just like Word2Vec file above. Let's make this concrete with an example. You can download the smallest GloVe pre-trained model from the GloVe\n",
        "website. It an 822 Megabyte zip file with 4 different models (50, 100, 200 and 300-dimensional vectors) trained on Wikipedia data with 6 billion tokens and a 400,000 word vocabulary.\n",
        "\n",
        "```python\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "glove_input_file = 'glove.6B.100d.txt'\n",
        "word2vec_output_file = 'glove.6B.100d.txt.word2vec'\n",
        "glove2word2vec(glove_input_file, word2vec_output_file)\n",
        "```\n",
        "\n",
        "You now have a copy of the GloVe model in Word2Vec format with the filename glove.6B.100d.txt.word2vec. Now we can load it and perform the same (king - man) + woman = ? test as in the previous section.\n",
        "\n",
        "```python\n",
        "from gensim.models import KeyedVectors\n",
        "# load the Stanford GloVe model\n",
        "filename = 'glove.6B.100d.txt.word2vec'\n",
        "model = KeyedVectors.load_word2vec_format(filename, binary=False)\n",
        "# calculate: (king - man) + woman = ?\n",
        "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
        "```\n",
        "\n",
        "Pulling all of this together.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCvm87PGpw-U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "af2624ab-4f68-49b9-fa0f-f68498c67477"
      },
      "source": [
        "# download glove.6B \n",
        "download_file(BIG_URLS['g2v'][0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "requesting URL: http://nlp.stanford.edu/data/glove.6B.zip\n",
            "remote size: 862182613\n",
            "local size: None\n",
            "Downloading to ./glove.6B.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./glove.6B.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRw5tWoFquxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# unzip zip file\n",
        "\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('glove.6B.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('glove')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W2m4jN-JHEG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "ca7b6814-8fdb-46fb-c9ca-6b6c3cb220ad"
      },
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# convert glove to word2vec format\n",
        "glove_input_file = 'glove/glove.6B.100d.txt'\n",
        "word2vec_output_file = 'glove.6B.100d.txt.word2vec'\n",
        "glove2word2vec(glove_input_file, word2vec_output_file)\n",
        "\n",
        "# load the converted model\n",
        "filename = 'glove.6B.100d.txt.word2vec'\n",
        "model = KeyedVectors.load_word2vec_format(filename, binary=False)\n",
        "\n",
        "# calculate: (king - man) + woman = ?\n",
        "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
        "print(result)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[('queen', 0.7698541283607483)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6ub443zzPtw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "59f16e29-c831-464c-c4e7-f06b2eedbe68"
      },
      "source": [
        "# find the top 2 most similar words\n",
        "result = model.most_similar_cosmul(positive=['woman', 'king'], negative=['man'], topn=2) \n",
        "print(result)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('queen', 0.8964555859565735), ('monarch', 0.8495979309082031)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6f9pur4zQam",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "2b9c0d76-21e1-4887-eab1-f1785119fe5a"
      },
      "source": [
        "# find the top-N most similar words\n",
        "result = model.most_similar_cosmul(positive=['woman', 'king'], negative=['man']) \n",
        "print(result)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('queen', 0.8964555859565735), ('monarch', 0.8495979309082031), ('throne', 0.8447030782699585), ('princess', 0.8371668457984924), ('elizabeth', 0.835679292678833), ('daughter', 0.8348594307899475), ('prince', 0.8230059742927551), ('mother', 0.8154449462890625), ('margaret', 0.8147734999656677), ('father', 0.8100855350494385)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZO4Z-3UzDr4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "3263dad7-f093-4ed7-b725-67af6777a7c1"
      },
      "source": [
        "# filter not similer word\n",
        "print(model.doesnt_match('breakfast cereal dinner lunch').split())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ5wufAxzkQG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "3f863a72-90dd-4439-f27f-b86c405c9491"
      },
      "source": [
        "similarity = model.similarity('woman', 'man')\n",
        "print(similarity)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8323495\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VBpaOUDzqRg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "5e537004-0a8e-4fd1-c4a7-0d99a5ef7656"
      },
      "source": [
        "result = model.similar_by_word('cat')\n",
        "print(result)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('dog', 0.8798074722290039), ('rabbit', 0.7424426674842834), ('cats', 0.7323004007339478), ('monkey', 0.7288709878921509), ('pet', 0.7190139889717102), ('dogs', 0.7163872718811035), ('mouse', 0.6915250420570374), ('puppy', 0.6800068020820618), ('rat', 0.6641027331352234), ('spider', 0.6501135230064392)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRxV2qjNzsE7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b4492f9a-3c32-4174-d56e-f4863fdb0af0"
      },
      "source": [
        "sentence_obama = 'Obama speaks to the media in Illinois'.lower().split()\n",
        "sentence_president = 'The president greets the press in Chicago'.lower().split()\n",
        "similarity = model.wmdistance(sentence_obama, sentence_president)\n",
        "print(similarity)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.4892687395218687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xac60HZzztnM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "4aab0ad3-3ddd-48c9-efd8-c2544432112b"
      },
      "source": [
        "distance = model.distance(\"media\", \"media\")\n",
        "print(distance)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.960464477539063e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}